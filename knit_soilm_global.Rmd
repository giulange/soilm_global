---
title: "SOILM_GLOBAL"
author: "Beni Stocker"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    toc_float: true
header-includes:
   - \usepackage{amsmath}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r echo=FALSE}
mycurve <- function( func, from, to, col='black', add=FALSE, lwd=1, lty=1 ){
  range_x <- seq( from, to, by=(to-from)/100 )
  range_y <- sapply( range_x, func )
  if (add){
    lines( range_x, range_y, type="l", col=col, lwd=lwd, lty=lty )
  } else {
    plot( range_x, range_y, type="l", col=col, lwd=lwd, lty=lty )
  }
}

```

This RMarkdown file is compiled with code from the publicly accessible github repository [github.com/stineb/soilm_global](https://github.com/stineb/soilm_global).

The starting point of this analysis is that we found that all the remote sensing-driven GPP models that we looked at have a tendency to overestimate GPP during conditions when soils are dry. Apparently, the apparent fractional reduction in light use efficiency, fLUE, which I derived in the previous paper using artificial neural networks, is strongly related - both in magnitude and timing - to the model biases. Below, I'm showing this, derive an empirical correction factor to account for soil moisture limitation on GPP, and assess implications of this mechanism for global GPP variability. 

## **The problem**: high bias in simulated GPP under dry conditions

### Pooled data from all available sites

First, collect FLUXNET 2015 data, environmental forcing data and P-model output into a common dataframe. This performs a data "cleaning" of FLUXNET 2015 data (see `clean_fluxnet.R`), calculates additional variables (e.g. soilm_obs_mean) and writes all data as an R data frame (tibble, `data/df_modobs_<simsuite>_*.Rdata`).
```{r get_modobs, echo=FALSE}
source("get_modobs.R")
simsuite <- "fluxnet2015"
outputset <- c( "s15" )
if (!file.exists( paste0( "data/df_modobs_fluxnet2015_", paste( outputset, collapse="_"), "_with_SWC_v4.Rdata" ) ) ) get_modobs( simsuite = simsuite, outputset = outputset )
```

Then, combine this with GPP data from BESS, VPM, MODIS and MTE, and aggregate all site data into a single dataframe (tibble, `data/nice_all_agg.Rdata` for daily data, and `data/nice_all_8d_agg_.Rdata` for data aggregated to 8 days).
```{r aggregate_all, warning=FALSE, eval=FALSE}
# source("aggregate_all_fluxnet2015.R")
```

After pooling all data and calculating the bias of simulated GPP from different products (P-model, MODIS MOD17A2H GPP, FLUXCOM MTE) as the ratio of modelled over observed, the problem becomes evident (see boxplots below). There is a systematic relationship between the bias and soil dryness. This ratio is always higher under dry conditions (daily AET/PET>0.5) than under well-watered. It's a bit weird for FLUXCOM MTE and MODIS, where there is a substantial negative bias under well-watered conditions, but no bias under dry conditions - just all shifted to too low simulated GPP. The P-model is better behaved, having no bias under well-watered conditions, but a tendency to an increasingly high positive bias with declining daily AET/PET and soil moisture values (calculated using the SPLASH model).  The same is true for MTE and MODIS GPP, although the pattern is not as clear (not shown). Here the P-model is driven using EVI for quantifying fAPAR. This is arguably implausible. We are working on a re-calibration of the light utilisation parameter in the P-model in combination with actual fAPAR data which has generally higher values than EVI.
```{r plot_all, fig.width=5, fig.height=4, eval=TRUE, message=FALSE, warning=FALSE}
# source("plot_bias_all.R")
```

### Pooled data from soil moisture focus sites

For a subset of the FLUXNET Tier 1 sites, a clear soil moisture control on light use efficiency is evident from the parallel CO2 flux, VPD, and and soil moisture data. These sites were used in the paper we have submitted and allow us here to investigate the bias in GPP model predictions to be related to the degree of soil moisture limitation. The latter is quantified by fLUE, the fractional of light use efficiency reduction due to soil moisture.

First, aggregate data for the subset of these 71 sites only. This also reads originally downloaded MODIS GPP files and saves data for each site as Rdata files.
```{r aggregate_nn, warning=FALSE, eval=FALSE}
# source("aggregate_nn_fluxnet2015.R")
```

Then align data along the start of "fLUE droughts". This also aggregates across drought events for each site and thereby quantifies the mean course of variables through drought events (not shown). Furthermore, this retains only datapoints that are either 20 days before the onset of a drought or during droughts and thereby allows us to focus on model bias associated with soil dryness. This uses only data with successcode 1, i.e. where a certain minimum number of days in the data were classified as *fLUE drought* in Stocker et al. (subm.).
```{r align, warning=FALSE, eval=FALSE}
# source("execute_reshape_align_nn_fluxnet2015.R")
```
For all GPP models, this shows a clear relationship between the apparent fractional reduction in light use efficiency (fLUE) and the model bias. Here, the ratio of observed-to-modelled is shown along the y-axes, indicating by how much modelled GPP would have to be scaled in order to match observations.  The straight red line is the 1:1 line and the fact that points cluster along it indicates that soil moisture effects on LUE are the dominant factor underlying model bias. Colors indicate the density of points. Small boxes with horizontal red lines show the most frequent value from a kernel density within fLUE bins and the vertical extent of the boxes the range of values where the kernel density lies above half its peak. The boxes to the right of each plot represent model bias (median, IQR) during the 20 days before fLUE drought onset.

```{r plot_bias, eval=TRUE, message=FALSE, warning=FALSE}
source("plot_bias_nn.R")
```
![*Bias vs. fLUE*](./fig/bias_vs_fvar.pdf)

## **The solution**: Fitting an empirical soil moisture stress function
As documented above, there is a systematic bias of several remote-sensing based GPP models during droughts and this bias is strongly related, both in magnitude and timing, to the apparent effects of soil moisture on light use efficiency. These apparent effects are quantified by 'fLUE', derived with artificial neural networks as described in Stocker et al. (2018). In addition, we found in Stocker et al. (2018) that the sensitivity of LUE to progressive soil dryness is related to the mean aridity at the site. I.e., the dryness-related decline in LUE is particularly strong at the driest sites (mostly deserts, grasslands, savannahs), whereas sites at intermediate aridity (mostly mediterranean) exhibit a smaller maximum reduction in LUE.

The functional form of fLUE (here termed $\varphi$) versus soil moisture ($\theta$) is suggestive of a quadratic function that attains 1 for soil moisture above a certain threshold $\theta_0$ and held at 1 for soil moisture values above that (see Fig. 7 in Stocker et al., 2018), and has a y-axis intersect ($\varphi_0$) related to mean annual AET/PET, (see Fig. 7 in Stocker et al., 2018). The latter reflects the relationship between soil dryness sensitivity of LUE and mean aridity of the site. This soil moisture stress function ($\varphi(\theta)$) is described by:
$$
    \varphi =
\begin{cases}
    \beta(\theta - \theta_0)^2 + 1,& \theta \leq \theta_0\\
    1,              & \theta > \theta_0
\end{cases}
$$
where the "curvature coefficient" $\beta$ is defined by the maximum LUE reduction ($\varphi_0$) at low soil moisture ($\theta$=0), leading to $\beta=(\varphi_0-1)/\theta_0^2$. $\varphi_0$ is a linear function of the mean annual AET/PET, termed $\alpha$:
$$
\varphi_0 = a + b \alpha
$$

Here, I'm using these relationships to fit an empirical function that represents direct soil moisture effects on LUE.

I tested several approaches to fit parameters $a$ and $b$. Best results were obtained by prescribing $\theta_0$ to 0.9 based on visual inspection of the functional form $\varphi(\theta)$ in Fig. 7 of Stocker et al. (2018). To illustrate this, I document two approaches below.


### Approach I

This uses the relationship between minimum fLUE and mean AET/PET, identified in Stocker et al. (2018). In the first step, a linear fit is derived between $\alpha$ at the respective site and $\varphi_0$, where $\varphi_0$ is derived from the data using the neural network method by Stocker et al. (2018). This defines parameters $a$ and $b$, and hence $\beta$ in above equations. $\varphi_0$ is the mean fLUE in the lowest soil moisture quartile. This is identical to the linear regression of fLUE$_0$ to soil moisture shown in Stocker et al. (2018) Fig. 9.
```{r linearfit1a, message=FALSE, warning=FALSE, echo=FALSE}
library(dplyr)
load( "data/nice_nn_agg_lue_obs_evi.Rdata" )       # loads 'nice_agg'
ddf <- nice_agg

## Use only sites where NN method worked (i.e. that had clear and identifiable soil moisture limitation)
successcodes <- read.csv( paste0( myhome, "/sofun/utils_sofun/analysis_sofun/fluxnet2015/successcodes.csv" ), as.is = TRUE )
do.sites <- dplyr::filter( successcodes, successcode==1 | successcode==2 )$mysitename
ddf <- ddf %>% filter( mysitename %in% do.sites )

## Merge mean annual alpha (AET/PET) values into this dataframe
load( "../sofun/utils_sofun/analysis_sofun/fluxnet2015/data/alpha_fluxnet2015.Rdata" )  # loads 'df_alpha'
ddf <- ddf %>% left_join( rename( df_alpha, meanalpha=alpha ), by="mysitename" )
source("get_linearfit.R")
source("plot_linearfit.R")

# usesites <- read.csv("use_biaseval.csv") %>% mutate( use_biaseval=ifelse(is.na(use_biaseval), FALSE, TRUE ) )
linearfit_1a  <- get_linearfit( filter( ddf, ratio_obs_mod_pmodel < 5 ), monthly=FALSE )
save( linearfit_1a,  file="data/linearfit_1a.Rdata" )
plot_linearfit( linearfit_1a )
```

In summary, this method derives the following fitting parameters: 
```{r}
print( linearfit_1a$linmod )
```

Given the estimate of $\varphi_0$ as a function of $\alpha$ at each site, we can calculate the soil moisture stress function using daily varying soil moisture data and evaluate whether accounting for this resolves the bias of modelled GPP at low soil moisture. Here, I'm assessing this with GPP predictions from the P-model.
```{r correct_linearfit1a, message=FALSE, warning=FALSE, echo=FALSE}
source("calc_flue_est_alpha.R")

## add estimated fLUE to ddf
ddf <- ddf %>% mutate( flue_est = calc_flue_est_alpha( soilm_mean, alpha=meanalpha, apar=coef(linearfit_1a$linmod)[1], bpar=coef(linearfit_1a$linmod)[2], cpar=0.125, dpar=0.75 ) )

## evaluate bias~soil moisture
nbins <- 5
binwidth <- 1/nbins
alphabins <- seq( from=0, to=1, by=binwidth )
soilmbins <- seq( from=0, to=1, by=binwidth )
ddf <- ddf %>% mutate( inalphabin = cut( as.numeric(alpha), breaks = alphabins ), insoilmbin = cut( as.numeric(soilm_mean), breaks = soilmbins ) )

bp <- boxplot( log( bias_pmodel ) ~ insoilmbin, data=ddf, col="tomato", las=1, outline = FALSE, na.rm=TRUE, add=FALSE, at=(soilmbins[1:nbins]+1/nbins*0.3), boxwex=0.03, xlim=c(0,1), ylab="log of obs./mod.", xlab="soil moisture bins" )
bp <- boxplot( log( bias_pmodel * flue_est ) ~ insoilmbin, data=ddf, col="royalblue3", las=1, outline = FALSE, na.rm=TRUE, add=TRUE, at=(soilmbins[1:nbins]+1/nbins*0.6), boxwex=0.03, axes=FALSE, xlim=c(0,1) )
abline( h=0.0, lty=3 )
legend("bottomleft", c("P-model", "P-model, corrected"), bty="n", fill=c("tomato", "royalblue3") )
```

Above boxplot shows that the bias in predicted GPP is reduced but not resolved. Apparently, the predicted LUE reduction at low soil moisture is generally not strong enough.


<!-- ### Approach Ib: Fitting to fLUE using drought data only -->

<!-- All is done identically as above, but now loading a the dataset `df_dday_agg` from file `data/data_aligned_agg.Rdata`. -->
<!-- ```{r linearfit1b, message=FALSE, warning=FALSE, echo=FALSE} -->
<!-- load( "data/data_aligned_agg.Rdata" )     # loads 'df_dday_agg', etc. -->
<!-- ddf <- df_dday_agg -->
<!-- rm("df_dday_agg")  # rename to be a bit more concise -->

<!-- ## Use only sites where NN method worked (i.e. that had clear and identifiable soil moisture limitation) -->
<!-- successcodes <- read.csv( paste( myhome, "sofun/utils_sofun/analysis_sofun/fluxnet2015/successcodes.csv", sep="" ), as.is = TRUE ) -->
<!-- do.sites <- dplyr::filter( successcodes, successcode==1 | successcode==2 )$mysitename -->
<!-- ddf <- ddf %>% filter( mysitename %in% do.sites ) -->

<!-- ## Merge mean annual alpha (AET/PET) values into this dataframe -->
<!-- load( "../sofun/utils_sofun/analysis_sofun/fluxnet2015/data/alpha_fluxnet2015.Rdata" )  # loads 'df_alpha' -->
<!-- ddf <- ddf %>% left_join( rename( df_alpha, meanalpha=alpha ), by="mysitename" ) -->
<!-- source("get_linearfit.R") -->
<!-- source("plot_linearfit.R") -->

<!-- # usesites <- read.csv("use_biaseval.csv") %>% mutate( use_biaseval=ifelse(is.na(use_biaseval), FALSE, TRUE ) ) -->
<!-- linearfit_1b  <- get_linearfit( filter( filter( ddf, ratio_obs_mod_pmodel<5 & dday >=0 ), ratio_obs_mod_pmodel < 5 ), monthly=FALSE ) -->
<!-- save( linearfit_1b,  file="data/linearfit_1b.Rdata" ) -->
<!-- # plot_linearfit( linearfit_1b ) -->
<!-- ``` -->

<!-- In summary, this method derives the following fitting parameters:  -->
<!-- ```{r} -->
<!-- print( linearfit_1b$linmod ) -->
<!-- ``` -->

<!-- Given the estimate of $\varphi_0$ as a function of $\alpha$ at each site, we can calculate the soil moisture stress function using daily varying soil moisture data and evaluate whether accounting for this resolves the bias of modelled GPP at low soil moisture. Here, I'm assessing this with GPP predictions from the P-model. -->
<!-- ```{r correct_linearfit1b, message=FALSE, warning=FALSE, echo=FALSE} -->
<!-- source("calc_flue_est_alpha.R") -->

<!-- ## add estimated fLUE to ddf -->
<!-- ddf <- ddf %>% mutate( flue_est = calc_flue_est_alpha( soilm_mean, alpha=meanalpha, apar=coef(linearfit_1b$linmod)[1], bpar=coef(linearfit_1b$linmod)[2], cpar=0.125, dpar=0.75 ) ) -->

<!-- ## evaluate bias~soil moisture -->
<!-- nbins <- 5 -->
<!-- binwidth <- 1/nbins -->
<!-- alphabins <- seq( from=0, to=1, by=binwidth ) -->
<!-- soilmbins <- seq( from=0, to=1, by=binwidth ) -->
<!-- ddf <- ddf %>% mutate( inalphabin = cut( as.numeric(alpha), breaks = alphabins ), insoilmbin = cut( as.numeric(soilm_mean), breaks = soilmbins ) ) -->

<!-- bp <- boxplot( log( bias_pmodel ) ~ insoilmbin, data=ddf, col="tomato", las=1, outline = FALSE, na.rm=TRUE, add=FALSE, at=(soilmbins[1:nbins]+1/nbins*0.3), boxwex=0.03, xlim=c(0,1), ylab="log of obs./mod.", xlab="soil moisture bins" ) -->
<!-- bp <- boxplot( log( bias_pmodel * flue_est ) ~ insoilmbin, data=ddf, col="royalblue3", las=1, outline = FALSE, na.rm=TRUE, add=TRUE, at=(soilmbins[1:nbins]+1/nbins*0.6), boxwex=0.03, axes=FALSE, xlim=c(0,1) ) -->
<!-- abline( h=0.0, lty=3 ) -->
<!-- legend("bottomleft", c("P-model", "P-model, corrected"), bty="n", fill=c("tomato", "royalblue3") ) -->
<!-- ``` -->

<!-- Above boxplot shows that the bias in predicted GPP is reduced but not resolved. Apparently, the predicted LUE reduction at low soil moisture is generally not strong enough. Therefore, I tried another method. -->


### Approach II: Fitting to the model bias

In contrast to the method above, I'm fitting parameters $a$ and $b$ not to the maximum fLUE reduction, but directly to the bias in modelled versus observed GPP (for the P-model), i.e. to the ratio of observed over modelled GPP as a function of soil moisture.First, a quadratic function of the form described above (Eq. XXX) is fitted to the ratio of observed versus modelled GPP for each site individually. This yields a site-specific relationship of model bias with soil moisture and defines the maximum LUE reduction (or LUE correction) at low soil moisture ($\varphi_0$) for each site. Second, $\varphi_0$ is regressed to $\alpha$ as above.

```{r get_linearfit2_ratio, warning=FALSE, message=FALSE, echo=FALSE}
load( "data/data_aligned_agg.Rdata" )     # loads 'df_dday_agg', etc.
ddf <- df_dday_agg
rm("df_dday_agg")  # rename to be a bit more concise

## Use only sites where NN method worked (i.e. that had clear and identifiable soil moisture limitation)
successcodes <- read.csv( paste0( myhome, "/sofun/utils_sofun/analysis_sofun/fluxnet2015/successcodes.csv" ), as.is = TRUE )
do.sites <- dplyr::filter( successcodes, successcode==1 | successcode==2 )$mysitename
ddf <- ddf %>% filter( mysitename %in% do.sites )

## Merge mean annual alpha (AET/PET) values into this dataframe
load( "../sofun/utils_sofun/analysis_sofun/fluxnet2015/data/alpha_fluxnet2015.Rdata" )  # loads 'df_alpha'
ddf <- ddf %>% left_join( rename( df_alpha, meanalpha=alpha ), by="mysitename" )

## load additional functions
source("get_linearfit2.R")
source("stress_quad_1sided.R")

## Use fixed point (soil moisture) above which stress function is 1 (no stress)
x0_fix <- 0.9
linearfit2 <- get_linearfit2( filter( ddf, ratio_obs_mod_pmodel<5 & dday >=0 ), target="ratio_obs_mod_pmodel", monthly=FALSE, bin=FALSE, x0_fix=x0_fix, useweights = FALSE )
# linearfit2 <- get_linearfit2( filter( ddf, ratio_obs_mod_pmodel<5 & dday >=0 ), target="fvar", monthly=FALSE, bin=FALSE, x0_fix=x0_fix, useweights = TRUE )
save( linearfit2, file="data/linearfit2_ratio.Rdata" )
```

<!-- This generally leads to a stronger sensitivity to soil moisture across the whole aridity spectrum. Compare to the solid line to dashed line, where the solid line represents the regression from approach II and the dashed line from approach I. -->
<!-- ```{r plot_linearfit2_ratio, warning=FALSE, message=FALSE, echo=FALSE} -->
<!-- source("plot_linearfit2.R") -->
<!-- load("data/linearfit_1a.Rdata") -->

<!-- ## plot fLUE0 vs. mean alpha and functional relationship (data cloud and fitted line) for all sites. -->
<!-- # plot_linearfit2( linearfit2, linearfit_1a, df=ddf ) -->
<!-- ``` -->

This approach (II) effectively resolves the bias in P-model GPP predictions even at very low soil moisture, as shown by the boxplots below (logarithm of observed over modelled in soil moisture bins).
```{r correct_linearfit2_ratio, warning=FALSE, message=FALSE, echo=FALSE}
## add estimated fLUE to ddf
ddf <- ddf %>% mutate( flue_est = stress_quad_1sided_alpha( soilm_mean, meanalpha, x0_fix, coef(linearfit2$linmod)[["(Intercept)"]], coef(linearfit2$linmod)[["meanalpha"]] ) )

## re-define bins for evaluation
nbins <- 5
binwidth <- 1/nbins
alphabins <- seq( from=0, to=1, by=binwidth )
soilmbins <- seq( from=0, to=1, by=binwidth )
ddf <- ddf %>% mutate( inalphabin = cut( as.numeric(alpha), breaks = alphabins ), insoilmbin = cut( as.numeric(soilm_mean), breaks = soilmbins ) )

## plot boxplot: bias by soil moisture bin
bp1 <- boxplot( log( bias_pmodel ) ~ insoilmbin, data=ddf, col="tomato", las=1, outline = FALSE, na.rm=TRUE, add=FALSE, at=(soilmbins[1:nbins]+1/nbins*0.3), boxwex=0.05, xlim=c(0,1), ylab="log of obs./mod.", xlab="soil moisture bins"  )
bp4 <- boxplot( log( bias_pmodel * flue_est ) ~ insoilmbin, data=ddf, col="springgreen3", las=1, outline = FALSE, na.rm=TRUE, add=TRUE, at=(soilmbins[1:nbins]+1/nbins*0.7), boxwex=0.05, axes=FALSE, xlim=c(0,1) )
abline( h=0.0, lty=3 )
legend("bottomleft", c("P-model", "P-model, corrected"), bty="n", fill=c("tomato", "springgreen3") )
```

In summary, this method derives the following fitting parameters: 
```{r}
print( linearfit2$linmod )
```
This is the R code that implements this soil moisture stress function:
```{r empirical_function, eval=FALSE}
stress_quad_1sided_alpha <- function( x, alpha, x0, apar, bpar ){
	y0 <- apar + bpar * alpha
	beta <- (1 - y0) / x0^2
  outstress <- 1.0 - beta * ( x - x0 ) ^ 2
  outstress <- ifelse( x>x0, 1, outstress )
  return( outstress )
}
```
Here, `x0` is set to 0.9. `alpha` is $\alpha$ (AET/PET, mean over daily values per site), and `x` is soil moisture.


### Approach III: Fitting to the model bias directly

In contrast to the method above, I'm fitting parameters $a$ and $b$ not to the maximum fLUE reduction, but directly to the bias in modelled versus observed GPP (for the P-model), i.e. to the ratio of observed over modelled GPP as a function of soil moisture. First, a quadratic function of the form described above (Eq. XXX) is fitted to the ratio of observed versus modelled GPP for each site individually. This yields a site-specific relationship of model bias with soil moisture and defines the maximum LUE reduction (or LUE correction) at low soil moisture ($\varphi_0$) for each site. Second, $\varphi_0$ is regressed to $\alpha$ as above.

```{r get_linearfit3_ratio, warning=FALSE, message=FALSE, echo=FALSE}
## load additional functions
source("get_linearfit3.R")
source("stress_quad_1sided.R")

## Use fixed point (soil moisture) above which stress function is 1 (no stress)
linearfit3 <- get_linearfit3( filter( ddf, ratio_obs_mod_pmodel<5 & dday >=0 ), useweights=TRUE )
save( linearfit3, file="data/linearfit3_ratio.Rdata" )
```
This generally leads to a stronger sensitivity to soil moisture across the whole aridity spectrum. Compare to the solid line to dashed line, where the solid line represents the regression from approach II and the dashed line from approach I.

This approach (III) effectively resolves the bias in P-model GPP predictions across even at very low soil moisture, as shown by the boxplots below (logarithm of observed over modelled in soil moisture bins).
```{r correct_linearfit3_ratio, warning=FALSE, message=FALSE, echo=FALSE}
## add estimated fLUE to ddf
ddf <- ddf %>% mutate( flue_est = stress_quad_1sided_alpha( soilm_mean, meanalpha, 0.9, apar=coef(linearfit3)["apar"], bpar=coef(linearfit3)["bpar"] ) )

## re-define bins for evaluation
nbins <- 5
binwidth <- 1/nbins
alphabins <- seq( from=0, to=1, by=binwidth )
soilmbins <- seq( from=0, to=1, by=binwidth )
ddf <- ddf %>% mutate( inalphabin = cut( as.numeric(alpha), breaks = alphabins ), insoilmbin = cut( as.numeric(soilm_mean), breaks = soilmbins ) )

## plot boxplot: bias by soil moisture bin
bp1 <- boxplot( log( bias_pmodel ) ~ insoilmbin, data=ddf, col="tomato", las=1, outline = FALSE, na.rm=TRUE, add=FALSE, at=(soilmbins[1:nbins]+1/nbins*0.3), boxwex=0.05, xlim=c(0,1), ylab="log of obs./mod.", xlab="soil moisture bins"  )
bp4 <- boxplot( log( bias_pmodel * flue_est ) ~ insoilmbin, data=ddf, col="springgreen3", las=1, outline = FALSE, na.rm=TRUE, add=TRUE, at=(soilmbins[1:nbins]+1/nbins*0.7), boxwex=0.05, axes=FALSE, xlim=c(0,1) )
abline( h=0.0, lty=3 )
legend("bottomleft", c("P-model", "P-model, corrected"), bty="n", fill=c("tomato", "springgreen3") )
```

In summary, this method derives the following fitting parameters: 
```{r}
print( coef(linearfit3) )
```


```{r plot_linearfit3}
# source("plot_linearfit3.R")
# plot_linearfit3( linearfit_1a, linearfit2, linearfit3, ddf, nice_agg )
```

<!-- The following figures illustrate the empirical soil moisture stress function (red) and fLUE values at each site. Note that fLUE values themselves are not used for this fitting and that the y-axis intersect of the red curve is is a function of $\alpha$ at the site. -->

<!-- ![](fig/fit_to_bias_plot_per_site.pdf) -->


## **Implications**

After deriving an empirical correction function to remove the bias in the P-model during dry soil conditions, I applied this function (with $a$ and $b$ fitted using approach II) for global P-model simulations. Two simulations were carried out:

- `s0`: no additional soil moisture stress on GPP considered (original model version)
- `s1a`: with additional soil moisture stress, following parametrisation I
- `s1b`: with additional soil moisture stress, following parametrisation II
- `s1c`: with additional soil moisture stress, following parametrisation III

Using P-model results, I am visualising the soil moisture effects on the mean GPP and its interannual variability.

### Processing output files.
The following bash script uses CDO commands to derive statistics (mean, variance, relative variance) at the global and at the gridcell levels.
```{r, eval=FALSE}
system( "./proc_nc_fields.sh" )
```

### Soil moisture reduction of mean annual GPP

```{r map_effects_gpp_mean, echo=FALSE, warning=FALSE, message=FALSE}
source("map_effects_gpp_mean.R")
```

### Soil moisture effect on variance in annual GPP
```{r map_effects_gpp_var, echo=FALSE, warning=FALSE, message=FALSE}
source("map_effects_gpp_var.R")
```

### Soil moisture effect on relative variance in annual GPP
Relative variance is the absolute variance divided by the mean. I'm quantifying the **amplification factor** ($A$) of the relative variance in annual GPP, quantified as:
$$
A=\frac{\text{var}(GPP_{s1})\;\overline{GPP_{s0}}}{\text{var}(GPP_{s0})\;\overline{GPP_{s1}}}
$$
```{r map_effects_gpp_relvar, echo=FALSE, warning=FALSE, message=FALSE}
source("map_effects_gpp_relvar.R")
```

This shows that...

- Soil moisture effects on light use efficiency substantially reduce annual GPP. At the global level this is by around 15%.
- Additionally accounting for soil moisture limitation drastically increases the relative variance of annual GPP at the gridcell level. Below are the quantiles of the amplification factor of relative variance, shown also on the map above (see inset: empirical cumulative distribution function of the amplification factor on log scale axes).

- Accounting for soil moisture effects increases variability in annual GPP especially in semi-arid regions. These are the dominant drivers of carbon cycle variability at global and annual scales. How is global variability affected? (see below)

The mean amplification is:
```{r echo=FALSE}
load("data/ampl_relvar.Rdata")
print( paste( mean( vec )) )
```

The quantiles of the amplification factor are:
```{r echo=FALSE}
print( quantile( vec, probs=( c(0.5,0.75, 0.9, 0.95, 0.99, 0.999 ) ) ) )
```
This is also illustrated by the inset in the previous plot which shows the empirical cumulative distribution function of the amplification factor $A$.

### Implications for IAV of global GPP
Next, I'm assessing the effect of the soil moisture correction for interannual variability in GPP. Analysis shown above shows that the at the gridcell level, variance in annual GPP is substantially enhanced by soil moisture effects. Does this translate into an enhancement of the variance in global GPP?

Here, using the P-model, $A$ at the global scale is calculated to be:
```{r echo=FALSE}
nc <- nc_open( paste0( myhome, "/data/pmodel_fortran_output/gpp_pmodel_s0_RELVAR_GLOB.nc" ) )
relvar_s0 <- ncvar_get( nc, varid="gpp" )
nc_close(nc)

nc <- nc_open( paste0( myhome, "/data/pmodel_fortran_output/gpp_pmodel_s1_RELVAR_GLOB.nc" ) )
relvar_s1 <- ncvar_get( nc, varid="gpp" )
nc_close(nc)

print(relvar_s1/relvar_s0)
```
Hence, the relative variance (variance in global total annual GPP divided by its mean) does not increase. The contrary is the case: it even decreases slightly. How can this be understood? The suspicion is that this is the scale dependence, also found by Jung et al. (2017). This is investigated below.

#### Ahlstroem plot
First analysis, I quantified the "Ahlstroem-f" (see Eq. 1 in Ahlstroem et al., 2015). This index quantifies for each gridcell its contribution to global interannual variability. If it's positive, then the gridcell's variability is in sync with global anomalies, i.e. has a positive contribution to global anomalies - the bigger the value the bigger its contribution. If positive and negative values are equally frequent and big, they cancel each other out, leaving zero global interannual variability. It is defined as:
$$
f_j = \frac{\sum_t \frac{x_{jt}|X_t|}{X_t}}{\sum_t |X_t|}
$$
where $x_{jt}$ is the flux anomaly (departure from a long-term trend) for region $j$ at time $t$ (in years), and $X_t$ is the global flux anomaly, so that $X_t=\sum_j x_{jt}$. By this definition $f_j$ is the average relative anomaly $x_{jt}/X_t$ for region $j$, weighted with the absolute global anomaly $|X_t|$ (text copied from Ahlstroem et al., 2015).

Here, the flux anomaly $x_{jt}$ is the diference in detrended GPP from simulations `s1` and `s0`:
$$
x_{jt} = \Delta\text{GPP}_{s0} - \Delta\text{GPP}_{s1}
$$
where $\Delta\text{GPP}$ the annual anomaly from its mean linear trend over 1982-2011.

```{r plot_ahlstroem, warning=FALSE, message=FALSE}
source("plot_ahlstroem.R")
```

This shows that Australia, sub-tropical southern Africa, and other red-colored regions are counteracted by blue-colored regions. Regional responses are becoming decoupledat scales of 10-20 degrees. This becomes even more evident by the analysis below:

#### Jung plot
To look at the spatial scale-dependence of the amplification factor, I did a similar analysis as in Jung et al. (2017).

First, create grid definition files for remapping with CDO. These are stored in `./grids/` as text files.
```{r do_jung, warning=FALSE, eval=FALSE, message=FALSE}
source("define_grids.R")
source("regrid_jung.R")
```

Then evaluate the amplification of relative variance of annual GPP as a function of spatial resolution.
```{r plot_jung, warning=FALSE, message=FALSE}
source("plot_jung.R")
```

This figure shows the amplification factor with the solid line as the mean, and shaded areas as the 1%/99%, 5%/95%, 10%/90%, and 25%/75% quantile ranges. Apparently, **the soil moisture-related amplification of relative variance in annual GPP is scale dependent.** (I'll have to think of more human-friendly words to describe this result). The bias of common remote-sensing based GPP estimates under dry conditions does not translate into an underestimation of the IAV of global GPP. However, at the smaller scales, IAV is drastically underestimated when not accounting for soil moisture effects.

For most gridcells (within the lower and upper quartiles), the amplification factor only starts to decline around 20 degrees. This reflects the spatial scale of the patterns in the Ahlstroem plot above.

<!-- ## Additional analyses -->

<!-- ### Distribution of variance in annual GPP -->
<!-- Considering that the remote-sensing driven GPP models (below termed RS-models) have a commong high bias related to soil moisture effects on LUE, I expected that these models should also have a tendency to underestimate variability at the gridcell level. But what's the reference? I compared them to DGVMs from the TRENDY bunch. -->

<!-- Below, I'm plotting the distribution of gridcell-level variance and relative variance in annual GPP for different models. 30-year time series are available from the P-model (driven by fAPAR) and the two MTE products, and for the TRENDY models. For other RS-models (MOD17AH2, BESS, VPM), only 10 year time series are evaluated, but the general picture is the same.   -->
<!-- ```{r plot_gridcell_iav, warning=FALSE, message=FALSE} -->
<!-- source("plot_gridcell_iav.R") -->
<!-- ``` -->

<!-- The comparison of the P-model to other RS-models and to TRENDY DGVMs doesn't give a clear picture: -->

<!-- - The difference between P-model `s0` and `s1` doesn't look impressive in this plot (logarithmic x-axis!). -->
<!-- - P-model has a much higher variance (absolute and relative) in gridcell-level annual GPP than the two MTE products and BESS, but looks very similar to MOD17AH2 (that's the latest MODIS GPP) and VPM. However, note that MTE FLUXCOM has a variance that is about 2 orders of magnitude smaller than all the other's. BESS and MTE about one order of magnitude smaller. Huge discrepancies! -->
<!-- - Compared to TRENDY models, relative variance in the P-model middle-of-the-road, but the spread between models is very large (>1 order of magnitude). Moving from `s0` to `s1` (= additionally accounting for soil moisture limitation) induces a smaller change in relative variance than the order of the model spread. DGVMs don't really serve us here helping to discriminate whether accounting for the soil moisture effect moves the P-model (as a representant of RS-models) to a more realistic range (considering that DGVMs do acccount for soil moisture limitation and should therefore be more realistic). -->

<!-- I'm a bit unsre if and if so how I should use these results. But anyhow, the effort of looking into this wasn't in vain. It lead me on to another track, wich I will let you know about asap... -->

<!-- ### Extreme events -->
<!-- Accounting for the soil moisture effect should also affect the distribution of extreme events. With negative GPP extremes that are related to drought becoming more negative (additional GPP reduction by soil moisture), the tails of the distribution may get fatter. On the other hand, smaller events, otherwise not detected/simulated may be more frequent. -->

<!-- We applied Jakob's method to identify contingent GPP anomalies in time and space as extreme events. A binary 3D field (space x time) is defined with *true* for points where the GPP anomaly is in the lower 5% quantile w.r.t. the distribution of all values in space and time. The integral of these anomalies across contingent regions in space-time quantify extremes as the GPP "loss" in units of PgC yr$^{-1}$. We derived the distribution of these extremes using monthly aggregated outputs from the two P-model simulations.  -->

<!-- While the question at hand here sounds highly exciting, the results are not. The difference between the distribution is not that big. The top 20-or-so events are a bit bigger in the `s1` simulation (however, the top 1 and 2 events are bigger in the `s0` simulation). -->
<!-- ![](fig/extremes.pdf) -->


<!-- The gridcell-level change in variance shown by maps above should be clearly visible in its distribution function. Also at this scale, P-model suggests a much higher variability than MTE GPP. And again, the TRENDY model don't allow us to argue that when including soil moisture stress, we get closer to a (realistic) DGVM with a satellite-driven GPP estimate. There are some models out there that have an even larger variability than the P-model (e.g. LPJ-GUESS or LPX). I'm showing density plots with straight and with logarithmic axes. -->
<!-- ```{r plot_gridcell_iav, echo=FALSE, warning=FALSE} -->
<!-- source("plot_gridcell_iav.R") -->
<!-- ``` -->

<!-- In spite of the substantial amplification of variance in annual GPP at the gridcell level, the variance of *global* annual GPP is not affected by the soil moisture correction. -->

<!-- As shown in the figure below, adding the soil moisture limitation to the P-model (black dashed vs. black line) results in a wider distribution of annual GPP anomalies from the mean trend (a.k.a. interannual variability). MTE GPP has a much narrower distribution. Comparison to TRENDY models is not so clear: Some models have a very small interannual variability, some have a large one, comparable to P-model. However, it looks like the P-model has the largest IAV. I guess we cannot really constrain these global total GPP IAV values with (global scale) observations, can we? -->

<!-- ```{r plot_global_iav, echo=FALSE, warning=FALSE} -->
<!-- source("plot_global_iav.R") -->
<!-- ``` -->


<!-- This is due to counteracting contributions from different regions. -->
